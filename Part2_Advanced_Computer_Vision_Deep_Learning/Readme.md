The following are the lessons I have learned and mastered

1. Lesson 1: Advanced CNN architecture

I learned about advance CNN architectures and saw how region-based CNN such as FAST R-CNN have allowed for fast, localised object recognition in images.

2. YOLO

I learned and had hand on exerience about the YOLO multi-object detection model and work with a YOLO implementation.

3. RNN's

I explored how memory can be incorporated into a deep learning model using recurrent neural networkd (RNNs). Learned how RNNs can learn from and generate ordered sequences of

4. LSTM

I have read and watched the following materials

[1] [Colah's blog](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)
  
[2] [Edwin Chen's LSTM post](http://blog.echen.me/2017/05/30/exploring-lstms/)
  
[3] [Andrej Karpathy's lecture](https://www.youtube.com/watch?v=iX5V1WpxxkY)

5. Attention Mechanism

This is one of the most recent breakthrough in deepleaning! I learned how attention models work and also implement some basic code. My intuition was further developped by reading Harshall Lamba blog post on attention mechanism. You can access my basic code implementation [here]()

[1] [Harshall Lamba's attention mechanism blog](https://towardsdatascience.com/intuitive-understanding-of-attention-mechanism-in-deep-learning-6c9482aecf4f)
